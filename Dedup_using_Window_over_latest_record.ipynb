{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook to demonstrate de-duplication (DeDup) using Spark Windowing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "from pyspark.sql import Row, Window\n",
    "from pyspark.sql.types import ArrayType, StructField, StructType, StringType, IntegerType\n",
    "from pyspark.sql.functions import lit, row_number, asc, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting at: Thu, 2020-Jul-02 02:32:36\n"
     ]
    }
   ],
   "source": [
    "startTime = datetime.now(timezone.utc)\n",
    "print('Starting at:', startTime.strftime('%a, %Y-%b-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema of Deals\n",
    "deal_schema = 'DEAL_ID:int, DEAL_NAME:string, DEAL_TIMESTAMP:string, ACTIVE:boolean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DEAL_ID: integer (nullable = true)\n",
      " |-- DEAL_NAME: string (nullable = true)\n",
      " |-- DEAL_TIMESTAMP: string (nullable = true)\n",
      " |-- ACTIVE: boolean (nullable = true)\n",
      "\n",
      "Prior data set:\n",
      "+-------+-------------+-------------------+------+\n",
      "|DEAL_ID|    DEAL_NAME|     DEAL_TIMESTAMP|ACTIVE|\n",
      "+-------+-------------+-------------------+------+\n",
      "|    100|       Deal_1|2019-09-13 10:11:13|  true|\n",
      "|    200|      Deal_22|2020-02-29 00:00:01|  true|\n",
      "|    300|     Deal 333|2003-03-03 03:33:33|  true|\n",
      "|    400|My deal 40404|2018-07-15 07:15:00|  true|\n",
      "+-------+-------------+-------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prior_data = [(100, 'Deal_1', datetime(2019, 9, 13, 10, 11, 13).strftime('%Y-%m-%d %H:%M:%S'), True),\n",
    "              (200, 'Deal_22', datetime(2020, 2, 29, 0, 0, 1).strftime('%Y-%m-%d %H:%M:%S'), True),\n",
    "              (300, 'Deal 333', datetime(2003, 3, 3, 3, 33, 33).strftime('%Y-%m-%d %H:%M:%S'), True),\n",
    "              (400, 'My deal 40404', datetime(2018, 7, 15, 7, 15, 0).strftime('%Y-%m-%d %H:%M:%S'), True),\n",
    "]\n",
    "\n",
    "prior_data_df = spark.createDataFrame(prior_data, schema=deal_schema)\n",
    "prior_data_df.printSchema()\n",
    "print('Prior data set:')\n",
    "prior_data_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DEAL_ID: integer (nullable = true)\n",
      " |-- DEAL_NAME: string (nullable = true)\n",
      " |-- DEAL_TIMESTAMP: string (nullable = true)\n",
      " |-- ACTIVE: boolean (nullable = true)\n",
      " |-- age: integer (nullable = false)\n",
      "\n",
      "+-------+-------------+-------------------+------+---+\n",
      "|DEAL_ID|    DEAL_NAME|     DEAL_TIMESTAMP|ACTIVE|age|\n",
      "+-------+-------------+-------------------+------+---+\n",
      "|    100|       Deal_1|2019-09-13 10:11:13|  true|  1|\n",
      "|    200|      Deal_22|2020-02-29 00:00:01|  true|  1|\n",
      "|    300|     Deal 333|2003-03-03 03:33:33|  true|  1|\n",
      "|    400|My deal 40404|2018-07-15 07:15:00|  true|  1|\n",
      "+-------+-------------+-------------------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# mark entire dataset as history i.e. age=1\n",
    "existing_df = prior_data_df.withColumn('age', lit(1))\n",
    "existing_df.printSchema()\n",
    "existing_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DEAL_ID: integer (nullable = true)\n",
      " |-- DEAL_NAME: string (nullable = true)\n",
      " |-- DEAL_TIMESTAMP: string (nullable = true)\n",
      " |-- ACTIVE: boolean (nullable = true)\n",
      "\n",
      "New data set:\n",
      "+-------+-------------------+-------------------+------+\n",
      "|DEAL_ID|          DEAL_NAME|     DEAL_TIMESTAMP|ACTIVE|\n",
      "+-------+-------------------+-------------------+------+\n",
      "|    200|Deal AlphaBetaGamma|2020-02-29 23:59:59|  true|\n",
      "|    300|           Deal 333|2003-03-03 03:33:33| false|\n",
      "|    555|    Cinqo the Dealo|2020-05-05 00:55:55|  true|\n",
      "+-------+-------------------+-------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_data = [\n",
    "            # UPDATE\n",
    "            (200, 'Deal AlphaBetaGamma', datetime(2020, 2, 29, 23, 59, 59).strftime('%Y-%m-%d %H:%M:%S'), True),\n",
    "    \n",
    "            # DEACTIVATE\n",
    "            (300, 'Deal 333', datetime(2003, 3, 3, 3, 33, 33).strftime('%Y-%m-%d %H:%M:%S'), False),\n",
    "    \n",
    "            # NEW\n",
    "            (555, 'Cinqo the Dealo', datetime(2020, 5, 5, 0, 55, 55).strftime('%Y-%m-%d %H:%M:%S'), True),\n",
    "]\n",
    "\n",
    "new_data_df = spark.createDataFrame(new_data, schema=deal_schema)\n",
    "new_data_df.printSchema()\n",
    "print('New data set:')\n",
    "new_data_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DEAL_ID: integer (nullable = true)\n",
      " |-- DEAL_NAME: string (nullable = true)\n",
      " |-- DEAL_TIMESTAMP: string (nullable = true)\n",
      " |-- ACTIVE: boolean (nullable = true)\n",
      " |-- age: integer (nullable = false)\n",
      "\n",
      "+-------+-------------------+-------------------+------+---+\n",
      "|DEAL_ID|          DEAL_NAME|     DEAL_TIMESTAMP|ACTIVE|age|\n",
      "+-------+-------------------+-------------------+------+---+\n",
      "|    200|Deal AlphaBetaGamma|2020-02-29 23:59:59|  true|  0|\n",
      "|    300|           Deal 333|2003-03-03 03:33:33| false|  0|\n",
      "|    555|    Cinqo the Dealo|2020-05-05 00:55:55|  true|  0|\n",
      "+-------+-------------------+-------------------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# mark entire dataset as current i.e. age=0\n",
    "new_df = new_data_df.withColumn('age', lit(0))\n",
    "new_df.printSchema()\n",
    "new_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unified (merged) data set:\n",
      "+-------+-------------------+-------------------+------+---+\n",
      "|DEAL_ID|          DEAL_NAME|     DEAL_TIMESTAMP|ACTIVE|age|\n",
      "+-------+-------------------+-------------------+------+---+\n",
      "|    100|             Deal_1|2019-09-13 10:11:13|  true|  1|\n",
      "|    200|            Deal_22|2020-02-29 00:00:01|  true|  1|\n",
      "|    200|Deal AlphaBetaGamma|2020-02-29 23:59:59|  true|  0|\n",
      "|    300|           Deal 333|2003-03-03 03:33:33|  true|  1|\n",
      "|    300|           Deal 333|2003-03-03 03:33:33| false|  0|\n",
      "|    400|      My deal 40404|2018-07-15 07:15:00|  true|  1|\n",
      "|    555|    Cinqo the Dealo|2020-05-05 00:55:55|  true|  0|\n",
      "+-------+-------------------+-------------------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get ready for merge\n",
    "assert (existing_df.schema == new_df.schema)\n",
    "\n",
    "all_deals_df = existing_df.union(new_df)\n",
    "print('Unified (merged) data set:')\n",
    "# ORDER BY DEAL_ID ASC, AGE DESC\n",
    "all_deals_df.sort(asc('DEAL_ID'), all_deals_df.age.desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Windowsing operation\n",
    "window = Window.partitionBy('DEAL_ID').orderBy(asc('age')) # current i.e. age=0 should appear before previous i.e. age=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before processing for dedup:\n",
      "+-------+-------------------+-------------------+------+---+------+\n",
      "|DEAL_ID|          DEAL_NAME|     DEAL_TIMESTAMP|ACTIVE|age|rownum|\n",
      "+-------+-------------------+-------------------+------+---+------+\n",
      "|    100|             Deal_1|2019-09-13 10:11:13|  true|  1|     1|\n",
      "|    200|Deal AlphaBetaGamma|2020-02-29 23:59:59|  true|  0|     1|\n",
      "|    200|            Deal_22|2020-02-29 00:00:01|  true|  1|     2|\n",
      "|    300|           Deal 333|2003-03-03 03:33:33| false|  0|     1|\n",
      "|    300|           Deal 333|2003-03-03 03:33:33|  true|  1|     2|\n",
      "|    400|      My deal 40404|2018-07-15 07:15:00|  true|  1|     1|\n",
      "|    555|    Cinqo the Dealo|2020-05-05 00:55:55|  true|  0|     1|\n",
      "+-------+-------------------+-------------------+------+---+------+\n",
      "\n",
      "\n",
      "After processing for dedup:\n",
      "+-------+-------------------+-------------------+------+\n",
      "|DEAL_ID|          DEAL_NAME|     DEAL_TIMESTAMP|ACTIVE|\n",
      "+-------+-------------------+-------------------+------+\n",
      "|    100|             Deal_1|2019-09-13 10:11:13|  true|\n",
      "|    200|Deal AlphaBetaGamma|2020-02-29 23:59:59|  true|\n",
      "|    300|           Deal 333|2003-03-03 03:33:33| false|\n",
      "|    400|      My deal 40404|2018-07-15 07:15:00|  true|\n",
      "|    555|    Cinqo the Dealo|2020-05-05 00:55:55|  true|\n",
      "+-------+-------------------+-------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dedup_deals_df = all_deals_df.withColumn(\"rownum\", row_number().over(window))\n",
    "print('Before processing for dedup:')\n",
    "dedup_deals_df.orderBy('DEAL_ID').show()\n",
    "print()\n",
    "print('After processing for dedup:')\n",
    "dedup_success_df = dedup_deals_df \\\n",
    "                    .where('rownum == 1') \\\n",
    "                    .drop('rownum', 'age')\n",
    "dedup_success_df.orderBy('DEAL_ID').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_deal_name_before: Row(DEAL_NAME='Deal_22')\n",
      "test_deal_name_after: Row(DEAL_NAME='Deal AlphaBetaGamma')\n",
      "test_active_flag_before: [Row(ACTIVE=True)]\n",
      "test_active_flag_after: [Row(ACTIVE=False)]\n"
     ]
    }
   ],
   "source": [
    "# test for dedup for DEAL_NAME\n",
    "test_row_deal_name_before = prior_data_df.where('DEAL_ID == 200').select('DEAL_NAME').head()\n",
    "print('test_deal_name_before:', test_row_deal_name_before)\n",
    "test_row_deal_name_after = dedup_success_df.where('DEAL_ID == 200').select('DEAL_NAME').head()\n",
    "print('test_deal_name_after:', test_row_deal_name_after)\n",
    "assert (test_row_deal_name_before.DEAL_NAME != test_row_deal_name_after.DEAL_NAME)\n",
    "\n",
    "# test for dedup for ACTIVE\n",
    "test_list_active_flag_before = prior_data_df.where('DEAL_ID == 300').select('ACTIVE').collect()\n",
    "print('test_active_flag_before:', test_list_active_flag_before)\n",
    "test_list_active_flag_after = dedup_success_df.where('DEAL_ID == 300').select('ACTIVE').collect()\n",
    "print('test_active_flag_after:', test_list_active_flag_after)\n",
    "assert (test_list_active_flag_before[0] != test_list_active_flag_after[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed at: Thu, 2020-Jul-02 02:32:42\n"
     ]
    }
   ],
   "source": [
    "stopTime = datetime.now(timezone.utc)\n",
    "print('Completed at:', stopTime.strftime('%a, %Y-%b-%d %H:%M:%S'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
