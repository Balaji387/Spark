{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CSV file partitioned by folder structure /yyyy/mm/dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current in folder: /Users/chawl001/Dev/Python/Spark\n",
      "./test_data/csv_data/.DS_Store\n",
      "./test_data/csv_data/yyyy=2020/.DS_Store\n",
      "./test_data/csv_data/yyyy=2020/mm=05/dd=31/user_orig.csv\n",
      "./test_data/csv_data/yyyy=2020/mm=06/dd=18/user_latest.csv\n",
      "./test_data/csv_data/yyyy=2020/mm=06/dd=15/user_day2.csv\n"
     ]
    }
   ],
   "source": [
    "# start in parent of /test_data/ folder\n",
    "import os\n",
    "\n",
    "BASE_DATA_FOLDER:str = './test_data/csv_data'\n",
    "\n",
    "def tree_printer(root_folder, ):\n",
    "    #print(f'Folder structure of {root_folder}')\n",
    "    for root_folder, dirs, files in os.walk(root_folder):\n",
    "        for d in dirs:\n",
    "            #print(os.path.join(root_folder, d))\n",
    "            tree_printer(root_folder=d)\n",
    "        for f in files:\n",
    "            print(os.path.join(root_folder, f))\n",
    "            \n",
    "print('Current in folder:', os.getcwd())\n",
    "tree_printer(root_folder=BASE_DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- USER_ID: string (nullable = true)\n",
      " |-- USER_NAME: string (nullable = true)\n",
      " |-- SESSION_ID: string (nullable = true)\n",
      " |-- LOG_IN_DT_TM: string (nullable = true)\n",
      " |-- LOGOUT_DT_TM: string (nullable = true)\n",
      " |-- yyyy: integer (nullable = true)\n",
      " |-- mm: integer (nullable = true)\n",
      " |-- dd: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df = spark.read.csv(BASE_DATA_FOLDER, header=True)\n",
    "user_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataframe:\n",
      "+-------+----------+-----------+-------------------+-------------------+----+---+---+\n",
      "|USER_ID| USER_NAME| SESSION_ID|       LOG_IN_DT_TM|       LOGOUT_DT_TM|yyyy| mm| dd|\n",
      "+-------+----------+-----------+-------------------+-------------------+----+---+---+\n",
      "|    100|    lalitc|123-456-789|2020-05-30 23:59:50|2020-05-31 20:21:22|2020|  5| 31|\n",
      "|    007|  bond_007|007-007-007|2020-05-31 07:07:57|2020-05-31 08:07:57|2020|  5| 31|\n",
      "|    101|  mt_baker|009-009-009|2020-05-31 10:10:10|2020-05-31 22:22:22|2020|  5| 31|\n",
      "|    007|  bond_007|007-007-777|2020-06-16 00:00:01|2020-06-16 23:59:59|2020|  6| 18|\n",
      "|    100|    lalitc|999-000-999|2020-06-16 03:30:33|2020-06-16 06:55:06|2020|  6| 18|\n",
      "|    100|    lalitc|000-888-000|2020-06-16 08:08:08|2020-06-16 09:08:08|2020|  6| 18|\n",
      "|    007|  bond_007|007-007-777|2020-06-15 01:01:01|2020-06-15 23:59:59|2020|  6| 15|\n",
      "|    111|mt_rainier|447-447-447|2020-06-15 09:00:00|2020-06-15 17:00:00|2020|  6| 15|\n",
      "+-------+----------+-----------+-------------------+-------------------+----+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Original Dataframe:')\n",
    "user_df.show(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repartitioned Dataframe:\n",
      "+-------+----------+-----------+-------------------+-------------------+----+---+---+\n",
      "|USER_ID| USER_NAME| SESSION_ID|       LOG_IN_DT_TM|       LOGOUT_DT_TM|yyyy| mm| dd|\n",
      "+-------+----------+-----------+-------------------+-------------------+----+---+---+\n",
      "|    101|  mt_baker|009-009-009|2020-05-31 10:10:10|2020-05-31 22:22:22|2020|  5| 31|\n",
      "|    007|  bond_007|007-007-007|2020-05-31 07:07:57|2020-05-31 08:07:57|2020|  5| 31|\n",
      "|    100|    lalitc|123-456-789|2020-05-30 23:59:50|2020-05-31 20:21:22|2020|  5| 31|\n",
      "|    007|  bond_007|007-007-777|2020-06-15 01:01:01|2020-06-15 23:59:59|2020|  6| 15|\n",
      "|    111|mt_rainier|447-447-447|2020-06-15 09:00:00|2020-06-15 17:00:00|2020|  6| 15|\n",
      "|    100|    lalitc|999-000-999|2020-06-16 03:30:33|2020-06-16 06:55:06|2020|  6| 18|\n",
      "|    100|    lalitc|000-888-000|2020-06-16 08:08:08|2020-06-16 09:08:08|2020|  6| 18|\n",
      "|    007|  bond_007|007-007-777|2020-06-16 00:00:01|2020-06-16 23:59:59|2020|  6| 18|\n",
      "+-------+----------+-----------+-------------------+-------------------+----+---+---+\n",
      "\n",
      "Writen repartitioned files at:  ./test_data/repartitioned_by_user_id/\n",
      "./test_data/repartitioned_by_user_id/.part-00051-78605948-c7a8-489a-b762-1a915d34c611-c000.csv.crc\n",
      "./test_data/repartitioned_by_user_id/._SUCCESS.crc\n",
      "./test_data/repartitioned_by_user_id/.part-00011-78605948-c7a8-489a-b762-1a915d34c611-c000.csv.crc\n",
      "./test_data/repartitioned_by_user_id/part-00000-78605948-c7a8-489a-b762-1a915d34c611-c000.csv\n",
      "./test_data/repartitioned_by_user_id/part-00051-78605948-c7a8-489a-b762-1a915d34c611-c000.csv\n",
      "./test_data/repartitioned_by_user_id/.part-00186-78605948-c7a8-489a-b762-1a915d34c611-c000.csv.crc\n",
      "./test_data/repartitioned_by_user_id/part-00011-78605948-c7a8-489a-b762-1a915d34c611-c000.csv\n",
      "./test_data/repartitioned_by_user_id/part-00186-78605948-c7a8-489a-b762-1a915d34c611-c000.csv\n",
      "./test_data/repartitioned_by_user_id/_SUCCESS\n",
      "./test_data/repartitioned_by_user_id/.part-00000-78605948-c7a8-489a-b762-1a915d34c611-c000.csv.crc\n",
      "./test_data/repartitioned_by_user_id/part-00092-78605948-c7a8-489a-b762-1a915d34c611-c000.csv\n",
      "./test_data/repartitioned_by_user_id/.part-00092-78605948-c7a8-489a-b762-1a915d34c611-c000.csv.crc\n",
      "+-------+----------+-----------+-------------------+-------------------+----+---+---+\n",
      "|USER_ID| USER_NAME| SESSION_ID|       LOG_IN_DT_TM|       LOGOUT_DT_TM|yyyy| mm| dd|\n",
      "+-------+----------+-----------+-------------------+-------------------+----+---+---+\n",
      "|    007|  bond_007|007-007-007|2020-05-31 07:07:57|2020-05-31 08:07:57|2020|  5| 31|\n",
      "|    007|  bond_007|007-007-777|2020-06-16 00:00:01|2020-06-16 23:59:59|2020|  6| 18|\n",
      "|    007|  bond_007|007-007-777|2020-06-15 01:01:01|2020-06-15 23:59:59|2020|  6| 15|\n",
      "|    100|    lalitc|123-456-789|2020-05-30 23:59:50|2020-05-31 20:21:22|2020|  5| 31|\n",
      "|    100|    lalitc|999-000-999|2020-06-16 03:30:33|2020-06-16 06:55:06|2020|  6| 18|\n",
      "|    100|    lalitc|000-888-000|2020-06-16 08:08:08|2020-06-16 09:08:08|2020|  6| 18|\n",
      "|    111|mt_rainier|447-447-447|2020-06-15 09:00:00|2020-06-15 17:00:00|2020|  6| 15|\n",
      "|    101|  mt_baker|009-009-009|2020-05-31 10:10:10|2020-05-31 22:22:22|2020|  5| 31|\n",
      "+-------+----------+-----------+-------------------+-------------------+----+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Repartitioned Dataframe:')\n",
    "user_df_partn_by_UserID = user_df.repartition('USER_ID')\n",
    "user_df_partn_by_UserID.sort('mm','dd').show(25)\n",
    "\n",
    "# write out the repartioned dataframe\n",
    "repartition_data_folder = './test_data/repartitioned_by_user_id/'\n",
    "user_df_partn_by_UserID.write.option(\"overwrite\",\"true\").csv(repartition_data_folder, header=True)\n",
    "\n",
    "print('Writen repartitioned files at: ', repartition_data_folder)\n",
    "tree_printer(root_folder=repartition_data_folder)\n",
    "\n",
    "reread_df = spark.read.csv(repartition_data_folder, header=True)\n",
    "reread_df.show(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-----------+-------------------+-------------------+----+---+---+\n",
      "|USER_ID| USER_NAME| SESSION_ID|       LOG_IN_DT_TM|       LOGOUT_DT_TM|yyyy| mm| dd|\n",
      "+-------+----------+-----------+-------------------+-------------------+----+---+---+\n",
      "|    101|  mt_baker|009-009-009|2020-05-31 10:10:10|2020-05-31 22:22:22|2020|  5| 31|\n",
      "|    100|    lalitc|123-456-789|2020-05-30 23:59:50|2020-05-31 20:21:22|2020|  5| 31|\n",
      "|    111|mt_rainier|447-447-447|2020-06-15 09:00:00|2020-06-15 17:00:00|2020|  6| 15|\n",
      "|    007|  bond_007|007-007-007|2020-05-31 07:07:57|2020-05-31 08:07:57|2020|  5| 31|\n",
      "+-------+----------+-----------+-------------------+-------------------+----+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dedup_df = reread_df.dropDuplicates(['USER_ID'])\n",
    "dedup_df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
